# Basic code 
import fed3bandit as f3b
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
import glob
import os

# Function to calculate and remove outliers using IQR method for each variable separately
def remove_outliers(df, column_name):
    Q1 = df[column_name].quantile(0.25)
    Q3 = df[column_name].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    # Remove outliers only for this variable (keeping other columns untouched)
    filtered_df = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]
    return filtered_df, lower_bound, upper_bound

# Define the directory and the search pattern
directory = r"put your directory here"
search_pattern = os.path.join(directory, "*put the file pattern*")


# Find all files that match the search pattern
file_list = glob.glob(search_pattern)

# Initialize an empty list to store individual results as dictionaries
results_list = []

# Loop through each file, read it into a DataFrame, and add the filename as a column
for file in file_list:
    df_obesity = pd.read_csv(file)  # Adjust this if your files are not CSV
    # Convert the "MM:DD:YYYY hh:mm:ss" column to datetime
    df_obesity['MM:DD:YYYY hh:mm:ss'] = pd.to_datetime(df_obesity['MM:DD:YYYY hh:mm:ss'])

    # Determine the latest date in the dataset
    latest_date = df_obesity['MM:DD:YYYY hh:mm:ss'].max()

    # Define the date range for the last 36 hours, adjust depending on your need
    start_date = latest_date - pd.Timedelta(hours=36)

    # Filter the data to include only the last 36 hours
    filtered_df = df_obesity[(df_obesity['MM:DD:YYYY hh:mm:ss'] >= start_date) & (df_obesity['MM:DD:YYYY hh:mm:ss'] <= latest_date)]
    df_obesity = filtered_df

    # Parse the timestamp column
    df_obesity['timestamp'] = pd.to_datetime(df_obesity.iloc[:, 0])

    # Calculate the duration in hours
    duration_hours = (df_obesity['timestamp'].max() - df_obesity['timestamp'].min()).total_seconds() / 3600

    # Clean poke time and retrieval time
    df_obesity['Poke_Time'] = pd.to_numeric(df_obesity['Poke_Time'], errors='coerce')
    df_obesity.loc[df_obesity['Poke_Time'] > 30, 'Poke_Time'] = np.nan

    df_obesity['Retrieval_Time'] = pd.to_numeric(df_obesity['Retrieval_Time'], errors='coerce')
    df_obesity['Retrieval_Time'] = df_obesity['Retrieval_Time'].replace("Timed_out", np.nan)
    df_obesity.loc[df_obesity['Retrieval_Time'] > 10, 'Retrieval_Time'] = np.nan

    # Remove outliers for 'Poke_Time' only
    df_obesity_poke_cleaned, poke_lower, poke_upper = remove_outliers(df_obesity, 'Poke_Time')

    # Remove outliers for 'Retrieval_Time' only
    df_obesity_retrieval_cleaned, retrieval_lower, retrieval_upper = remove_outliers(df_obesity, 'Retrieval_Time')

    # After removing outliers, calculate statistics for each variable separately
    poke_time_mean = df_obesity_poke_cleaned['Poke_Time'].mean()
    retrieval_time_mean = df_obesity_retrieval_cleaned['Retrieval_Time'].mean()
    retrieval_time_median = df_obesity_retrieval_cleaned['Retrieval_Time'].median()  # Added median calculation

    # Calculate true_left and mouse_left for the plot using the full dataset (without poke and retrieval outliers)
    true_left = f3b.true_probs(df_obesity, offset=5)[0]
    mouse_left = f3b.binned_paction(df_obesity, window=10)

    # Plotting
    fig, ax = plt.subplots(figsize=(12, 2))
    ax.plot(np.arange(len(true_left)), true_left, c="red", linewidth=2, alpha=1)
    ax.plot(np.arange(len(mouse_left)), mouse_left, c="midnightblue", linewidth=3)
    ax.set_ylabel("P(Left)")
    ax.set_xlabel("Trial")
    ax.set_title("Deterministic example (100-0)")
    sns.despine()
    plt.show()

    # Collecting results after outliers are removed per variable
    result = {
        "filename": os.path.basename(file),
        "duration_hours": duration_hours,
        "total_pellets": f3b.count_pellets(df_obesity),
        "total_pokes": f3b.count_pokes(df_obesity),
        "pokes_per_pellet": f3b.pokes_per_pellet(df_obesity),
        "accuracy": f3b.accuracy(df_obesity),
        "win_stay": f3b.win_stay(df_obesity),
        "lose_shift": f3b.lose_shift(df_obesity),
        "poke_time_mean": poke_time_mean,  # Mean after removing poke time outliers
        "retrieval_time_mean": retrieval_time_mean,  # Mean after removing retrieval time outliers
        "retrieval_time_median": retrieval_time_median,  # Median after removing retrieval time outliers
        "pokes/hour": f3b.count_pokes(df_obesity) / duration_hours,
        "pellets/hour": f3b.count_pellets(df_obesity) / duration_hours
    }

    results_list.append(result)

# Create the final DataFrame with merged parameters 
results_df1 = pd.DataFrame(results_list)

# Export the results to a CSV file named results_df1
results_df1.to_csv('results_df1.csv', index=False)

print("File list:", file_list)
